\section{Iterative Methods for Unconstrained Optimization}
\subsection{Lecture 8-10}
Before, we have iterative methods to solve linear and linear least squares system.

\textbf{Goal}: Solve more general problems of minimization.

An iterative algorithm is a procedure that produces an (infinite) sequence of points $\{x_k\}$, in $\mathbb R^n$ such that our sequence converges to a critical point of $f$ or to a point that satisfies the second order necessary conditions of optimality.

\subsubsection{Line Search Strategy}
Most Line Search Algorithms have the following procedure:

Choose a starting point $x_0$. For $k = 0,1,2,\ldots$
\begin{enumerate}
  \item Choose a search direction $d_k$.
  \item Choose a step length $\alpha_k > 0$ (that satisfies $f(x_k + \alpha_k d_k) < f(x_k)$)
  \item Update $x_{k+1} = x_k + \alpha_k d_k$
  \item Stop if a stopping criterion is satisfied.
\end{enumerate}
\begin{definition}[Line Search Strategy]
  At each iteration $k$, we choose a vector (search direction) $d_k \neq 0 \in \mathbb R^n$, then choose $\alpha_k > 0$ (step length) that approximately solves
$$\alpha_k \in \text{argmin } f(x_k + \alpha d_k)$$
Then we update $x_{k+1} = x_k + \alpha_k v_k$.
\end{definition}
\subsubsubsection{Finding Descent Direction}
\begin{definition}[Descent Direction]
  Let $x \in U \subseteq \mathbb R^n$ with $U$ being an open set. Then $d \in \mathbb R^n$ is a descent direction for $f$ at $x$ if there exists $\bar \alpha > 0$ such that $$x + \alpha d \in U, f(x + \alpha d) < f(x)$$ for all $0 < \alpha < \bar \alpha$.

  \bigskip So $f(x_{k+1}) < f(x_k)$.
\end{definition}
\begin{lemma}
  Let $f$ be sufficiently smooth on an open set $U$ and let $\bar x \in U$. Let $d \in \mathbb R^n$ satisfy $$\langle d, \nabla f(\bar x) \rangle = \nabla f(\bar x)^T d < 0$$ Then $d$ is a descent direction for $f$ at $\bar x$.

  \bigskip (i.e., the directional derivative of $f$ at $\bar x$ in the direction of $d$ is negative, so we know that it is the descent direction.)
\end{lemma}

The main difference between line search methods is the choice of the descent direction
\begin{problem}[Example]
  If $\nabla f(x) \neq 0$ then $d = - \nabla f(x)$ is a descent direction since
  $$d^T \nabla f(x) = -\nabla f(x)^T \nabla f(x) = - \|\nabla f(x) \|^2_2 < 0$$
  Another option is letting $d = -H^{-1} \nabla f(x)$ where $H \succ 0$ and $\nabla f(x) \neq 0$ since
  $$d^T \nabla f(x) = - \nabla f(x)^T H^{-1} \nabla f(x) < 0$$
  since $H \succ 0$, we have $H^{-1} \succ 0$, so $\nabla f(x)^T H^{-1} \nabla f(x) > 0$.
\end{problem}
\begin{theorem}[Existence of a Descent Direction]
  Let $f: \mathbb R^n \to \mathbb R$ be continuously differentiable and let $\bar x \in \mathbb R^n$. Assume that $d$ is a descent direction of $f$ at $\bar x$, so $$\nabla f(\bar x)^T d < 0$$ Then there exists $\delta > 0$ such that for every $\alpha \in (0, \delta]$, 
  $$f(\bar x + \alpha d) < f(\bar x)$$.
\end{theorem}
\begin{proof}[Proof]
  By Taylor's theorem, for all $x \in \mathbb R^n$, 
  $$f(x) = f(\bar x) + \nabla f(\bar x)^T (x - \bar x) + o(\|x - \bar x\|)$$
  Then
  $$f(\bar x + \alpha d) = f(\bar x) + \nabla f(\bar x)^T (\bar x + \alpha d - \bar x) + o(\|\bar x + \alpha d - \bar x\|)$$
  Simplifying gives
  $$f(\bar x + \alpha d) = f(\bar x) + \alpha \underbrace{\nabla f(\bar x)^T d}_{< 0} + o(\|\alpha d\|)$$ Rearranging and dividing both sides by $\alpha \|d\|$, we get
  $$\frac{f(\bar x + \alpha d) - f(\bar x)}{\alpha \|d\|} = \frac{\nabla f(\bar x)^T d}{\|d\|} + \frac{o(\|\alpha d\|)}{\alpha \|d\|}$$
  Taking the limit as $\alpha \to 0$, we get
  $$\lim_{\alpha \to 0} \frac{f(\bar x + \alpha d) - f(\bar x)}{\alpha \|d\|} = \frac{\nabla f(\bar x)^T d}{\|d\|}$$
  Since $\nabla f(\bar x)^T d < 0$, we know that the limit is negative. Then there exists $\delta > 0$ such that for all $\alpha \in (0, \delta]$, we have
  $$\frac{f(\bar x + \alpha d) - f(\bar x)}{\alpha \|d\|} < 0$$
\end{proof}

\subsubsubsection{Finding Step Size}
The process of finding the step size $\alpha_k$ is called line search. Some common choices for step size are as follows:
\begin{enumerate}
  \item $\alpha_k = \alpha$ (a constant) for every $k$
  \item Exact line search: $\alpha_k = \text{argmin}_{\alpha \geq 0} f(x_k + \alpha d_k)$
  \item Inexact line search: A step size $\alpha_k$ that achieves a sufficient decrease in $f$. One popular inexact line search conditions are called the Wolfe conditions.
\end{enumerate}
\begin{problem}[Exact Line Search]
  For exact line search, we define a new function
  $$\phi(\alpha) = f(x_k + \alpha d_k)$$
  We can differentiate w.r.t. $\alpha$ using the chain rule to obtain
  $$\phi' (\alpha) = \nabla f(x_k + \alpha d_k)^T d_k$$
  Then we set $\phi'(\alpha) = 0$ to obtain the critical point of $\phi$. Then we can use the second derivative test to determine if the critical point is a local minimizer. If it is, then we have found the optimal step size $\alpha_k$.
\end{problem}
\begin{definition}[Wolfe Conditions]
  Let $0 < c_1 < c_2 < 1$. The Wolfe conditions are
  \begin{enumerate}
    \item Sufficient decrease condition: $$f(x_k + \alpha d_k) \leq f(x_k) + c_1 \alpha \nabla f(x_k)^T d_k$$ or equivalently
    $$\phi(\alpha_k) \leq \phi(0) + c_1 \alpha \phi'(0)$$
    \item Curvature condition: $$\nabla f(x_k + \alpha d_k)^T d_k \geq c_2 \nabla f(x_k)^T d_k$$ or equivalently
    $$\phi'(\alpha_k) \geq c_2 \phi'(0)$$
  \end{enumerate}
\end{definition}
\begin{theorem}[Existence of Step Lengths that Satisfy Wolfe Conditions]
  Assume $f: \mathbb R^n \to \mathbb R$ is continuously differentiable. Let $d_k$ be a descent direction at $x_k$ and assume $f$ is bounded below along the ray $\{x_k + \alpha d_k: \alpha \geq 0\}$. Then if $0 < c_1 < c_2 < 1$ there exist intervals of step lengths satisfying the Wolfe conditions.
\end{theorem}
\begin{proof}[Proof]
  Omitted
\end{proof}
\subsubsubsection{Steepest Descent Method}
The steepest descent method is easy to implement as it requires the calculation of the gradient but not second derivatives. The descent direction at each iteration is chosen as $$d_k = - \nabla f(x_k)$$
\begin{lemma}
  Let $f: \mathbb R^n \to \mathbb R$ be continuously differentiable and let $\bar x \in \mathbb R^n$ such that $\nabla f(\bar x) \neq 0$. Then the optimal solution of the following minimization problem $$\min_{d \in \mathbb R^n} \{\nabla f(\bar x)^T d: \|d\|_2 = 1\}$$ is $$d^* = \frac{-\nabla f(\bar x)}{\|\nabla f(\bar x)\|_2}$$
\end{lemma}
\begin{proof}[Proof]
  By Cauchy-Schwarz inequality, we have
  $$\nabla f(\bar x)^T d \geq -\| \nabla f(\bar x)\|_2 \| d\|_2 = -\|\nabla f(\bar x)\|_2$$
  The smallest value of $d$ is $d = \frac{-\nabla f(\bar x)}{\|\nabla f(\bar x)\|_2}$ since if we plug in $d$ into the inequality, we get
  $$\nabla f(\bar x)^T \frac{-\nabla f(\bar x)}{\|\nabla f(\bar x)\|_2} = \frac{-\|\nabla f(\bar x)\|^2_2}{\|\nabla f(\bar x)\|_2}=-\|\nabla f(\bar x)\|_2$$
  So $d^* = \frac{-\nabla f(\bar x)}{\|\nabla f(\bar x)\|_2}$ is a minimizer of this problem.
\end{proof}
\subsubsection{Trust Region Strategy}
The difference in trust region strategy and line search strategy is that in line search strategy, we first choose the direction, then choose step size. In trust region, we first choose the step size, then we choose the direction.
\begin{definition}[Trust Region Strategy]
  In each iteration, we construct a model of $f$. That is, in each step we consider $m_k: \mathbb R^n \to \mathbb R$ that is a simple function that approximates $f$ well on some simple set $\Omega_k$ (the trust region) around our current approximation $x_k$. Then we find the new approximation $$\hat x = \text{argmin } m_k(x) \quad \text{$x \in \Omega_k$}$$
  A common model is the quadratic model $$m_k(x) = f(x_k) + \langle \nabla f(x_k), x - x_k \rangle + \frac{1}{2} \langle x - x_k, B_k(x - x_k) \rangle$$ where $B_k \approx \nabla^2 f(x_k)$ approximates the Hessian. If the values $f(\hat x)$ and $m_k(\hat x)$ are close, then we declare $x_{k+1} = \hat x$. Otherwise, we shrink the size of the trust region $\Omega_k$ and repeat the process.

  Usually $\Omega_k$ is a ball, ellipsoid, or a box around $x_k$.

  The main points are how to choose a model function $m_k$, and how to choose a trust region $\Omega_k$.
\end{definition}

\begin{problem}[Lagrange Multiplier Example]
  Maximize $f(x,y) = x^2 y$ subject to $g(x,y) = x^2 + y^2 = 1$. By using Lagrange multipliers, we know that the maximizer, $(x^*, y^*)$ satisfies $$\nabla f(x^*, y^*) = \lambda \nabla g(x^*, y^*)$$ We have 
  \begin{align*}
    \nabla g(x,y) &= \begin{bmatrix} 2x \\ 2y \end{bmatrix} \\
    \nabla f(x,y) &= \begin{bmatrix} 2xy \\ x^2 \end{bmatrix}
  \end{align*} Then, using Lagrange multipliers, we solve
  $$\begin{bmatrix} 2xy \\ x^{2} \end{bmatrix} = \lambda \begin{bmatrix} 2x \\ 2y \end{bmatrix}$$ Since we also have the constraint $x^2 + y^2 = 1$, we solve the system of equations
  \begin{align*}
    2xy &= 2\lambda x \\
    x^2 &= 2\lambda y \\
    x^2 + y^2 &= 1
  \end{align*}
  Solving it, we get $$(x, y) = \left(\pm \sqrt{\frac{2}{3}}, \pm \sqrt{\frac{1}{3}}\right), \quad \lambda = y$$
  Testing each point, we get that $\left(\sqrt{\frac{2}{3}}, \sqrt{\frac{1}{3}}\right)$ is the maximizer of $f$.
\end{problem}

