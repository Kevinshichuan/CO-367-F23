\section{Iterative Methods for Unconstrained Optimization}
\subsection{Lecture 8-10}
Before, we have iterative methods to solve linear and linear least squares system.

\textbf{Goal}: Solve more general problems of minimization.

An iterative algorithm is a procedure that produces an (infinite) sequence of points $\{x_k\}$, in $\mathbb R^n$ such that our sequence converges to a critical point of $f$ or to a point that satisfies the second order necessary conditions of optimality.

\subsubsection{Line Search Strategy}
Most Line Search Algorithms have the following procedure:

Choose a starting point $x_0$. For $k = 0,1,2,\ldots$
\begin{enumerate}
  \item Choose a search direction $d_k$.
  \item Choose a step length $\alpha_k > 0$ (that satisfies $f(x_k + \alpha_k d_k) < f(x_k)$)
  \item Update $x_{k+1} = x_k + \alpha_k d_k$
  \item Stop if a stopping criterion is satisfied.
\end{enumerate}
\begin{definition}[Line Search Strategy]
  At each iteration $k$, we choose a vector (search direction) $d_k \neq 0 \in \mathbb R^n$, then choose $\alpha_k > 0$ (step length) that approximately solves
$$\alpha_k \in \text{argmin } f(x_k + \alpha d_k)$$
Then we update $x_{k+1} = x_k + \alpha_k v_k$.
\end{definition}
\subsubsubsection{Finding Descent Direction}
\begin{definition}[Descent Direction]
  Let $x \in U \subseteq \mathbb R^n$ with $U$ being an open set. Then $d \in \mathbb R^n$ is a descent direction for $f$ at $x$ if there exists $\bar \alpha > 0$ such that $$x + \alpha d \in U, f(x + \alpha d) < f(x)$$ for all $0 < \alpha < \bar \alpha$.

  \bigskip So $f(x_{k+1}) < f(x_k)$.
\end{definition}
\begin{lemma}
  Let $f$ be sufficiently smooth on an open set $U$ and let $\bar x \in U$. Let $d \in \mathbb R^n$ satisfy $$\langle d, \nabla f(\bar x) \rangle = \nabla f(\bar x)^T d < 0$$ Then $d$ is a descent direction for $f$ at $\bar x$.

  \bigskip (i.e., the directional derivative of $f$ at $\bar x$ in the direction of $d$ is negative, so we know that it is the descent direction.)
\end{lemma}

The main difference between line search methods is the choice of the descent direction
\begin{problem}[Example]
  If $\nabla f(x) \neq 0$ then $d = - \nabla f(x)$ is a descent direction since
  $$d^T \nabla f(x) = -\nabla f(x)^T \nabla f(x) = - \|\nabla f(x) \|^2_2 < 0$$
  Another option is letting $d = -H^{-1} \nabla f(x)$ where $H \succ 0$ and $\nabla f(x) \neq 0$ since
  $$d^T \nabla f(x) = - \nabla f(x)^T H^{-1} \nabla f(x) < 0$$
  since $H \succ 0$, we have $H^{-1} \succ 0$, so $\nabla f(x)^T H^{-1} \nabla f(x) > 0$.
\end{problem}
\begin{theorem}[Existence of a Descent Direction]
  Let $f: \mathbb R^n \to \mathbb R$ be continuously differentiable and let $\bar x \in \mathbb R^n$. Assume that $d$ is a descent direction of $f$ at $\bar x$, so $$\nabla f(\bar x)^T d < 0$$ Then there exists $\delta > 0$ such that for every $\alpha \in (0, \delta]$, 
  $$f(\bar x + \alpha d) < f(\bar x)$$.
\end{theorem}
\begin{proof}[Proof]
  By Taylor's theorem, for all $x \in \mathbb R^n$, 
  $$f(x) = f(\bar x) + \nabla f(\bar x)^T (x - \bar x) + o(\|x - \bar x\|)$$
  Then
  $$f(\bar x + \alpha d) = f(\bar x) + \nabla f(\bar x)^T (\bar x + \alpha d - \bar x) + o(\|\bar x + \alpha d - \bar x\|)$$
  Simplifying gives
  $$f(\bar x + \alpha d) = f(\bar x) + \alpha \underbrace{\nabla f(\bar x)^T d}_{< 0} + o(\|\alpha d\|)$$ Rearranging and dividing both sides by $\alpha \|d\|$, we get
  $$\frac{f(\bar x + \alpha d) - f(\bar x)}{\alpha \|d\|} = \frac{\nabla f(\bar x)^T d}{\|d\|} + \frac{o(\|\alpha d\|)}{\alpha \|d\|}$$
  Taking the limit as $\alpha \to 0$, we get
  $$\lim_{\alpha \to 0} \frac{f(\bar x + \alpha d) - f(\bar x)}{\alpha \|d\|} = \frac{\nabla f(\bar x)^T d}{\|d\|}$$
  Since $\nabla f(\bar x)^T d < 0$, we know that the limit is negative. Then there exists $\delta > 0$ such that for all $\alpha \in (0, \delta]$, we have
  $$\frac{f(\bar x + \alpha d) - f(\bar x)}{\alpha \|d\|} < 0$$
\end{proof}

\subsubsubsection{Finding Step Size}
The process of finding the step size $\alpha_k$ is called line search. Some common choices for step size are as follows:
\begin{enumerate}
  \item $\alpha_k = \alpha$ (a constant) for every $k$
  \item Exact line search: $\alpha_k = \text{argmin}_{\alpha \geq 0} f(x_k + \alpha d_k)$
  \item Inexact line search: A step size $\alpha_k$ that achieves a sufficient decrease in $f$. One popular inexact line search conditions are called the Wolfe conditions.
\end{enumerate}
\begin{problem}[Exact Line Search]
  For exact line search, we define a new function
  $$\phi(\alpha) = f(x_k + \alpha d_k)$$
  We can differentiate w.r.t. $\alpha$ using the chain rule to obtain
  $$\phi' (\alpha) = \nabla f(x_k + \alpha d_k)^T d_k$$
  Then we set $\phi'(\alpha) = 0$ to obtain the critical point of $\phi$. Then we can use the second derivative test to determine if the critical point is a local minimizer. If it is, then we have found the optimal step size $\alpha_k$.
\end{problem}
\begin{definition}[Wolfe Conditions]
  Let $0 < c_1 < c_2 < 1$. The Wolfe conditions are
  \begin{enumerate}
    \item Sufficient decrease condition: $$f(x_k + \alpha d_k) \leq f(x_k) + c_1 \alpha \nabla f(x_k)^T d_k$$ or equivalently
    $$\phi(\alpha_k) \leq \phi(0) + c_1 \alpha \phi'(0)$$
    \item Curvature condition: $$\nabla f(x_k + \alpha d_k)^T d_k \geq c_2 \nabla f(x_k)^T d_k$$ or equivalently
    $$\phi'(\alpha_k) \geq c_2 \phi'(0)$$
  \end{enumerate}
\end{definition}
\begin{theorem}[Existence of Step Lengths that Satisfy Wolfe Conditions]
  Assume $f: \mathbb R^n \to \mathbb R$ is continuously differentiable. Let $d_k$ be a descent direction at $x_k$ and assume $f$ is bounded below along the ray $\{x_k + \alpha d_k: \alpha \geq 0\}$. Then if $0 < c_1 < c_2 < 1$ there exist intervals of step lengths satisfying the Wolfe conditions.
\end{theorem}
\begin{proof}[Proof]
  Omitted
\end{proof}
\subsubsubsection{Steepest Descent Method}
The steepest descent method is easy to implement as it requires the calculation of the gradient but not second derivatives. The descent direction at each iteration is chosen as $$d_k = - \nabla f(x_k)$$
\begin{lemma}
  Let $f: \mathbb R^n \to \mathbb R$ be continuously differentiable and let $\bar x \in \mathbb R^n$ such that $\nabla f(\bar x) \neq 0$. Then the optimal solution of the following minimization problem $$\min_{d \in \mathbb R^n} \{\nabla f(\bar x)^T d: \|d\|_2 = 1\}$$ is $$d^* = \frac{-\nabla f(\bar x)}{\|\nabla f(\bar x)\|_2}$$
\end{lemma}
\begin{proof}[Proof]
  By Cauchy-Schwarz inequality, we have
  $$\nabla f(\bar x)^T d \geq -\| \nabla f(\bar x)\|_2 \| d\|_2 = -\|\nabla f(\bar x)\|_2$$
  The smallest value of $d$ is $d = \frac{-\nabla f(\bar x)}{\|\nabla f(\bar x)\|_2}$ since if we plug in $d$ into the inequality, we get
  $$\nabla f(\bar x)^T \frac{-\nabla f(\bar x)}{\|\nabla f(\bar x)\|_2} = \frac{-\|\nabla f(\bar x)\|^2_2}{\|\nabla f(\bar x)\|_2}=-\|\nabla f(\bar x)\|_2$$
  So $d^* = \frac{-\nabla f(\bar x)}{\|\nabla f(\bar x)\|_2}$ is a minimizer of this problem.
\end{proof}
\begin{theorem}[]
  Let $\{x_k\}$ be the sequence generated by the method of steepest descent method where the step sizes are chosen by the exact line search. Then for every $k \geq 0, k \in \mathbb N$ $$(x_{k+2} - x_{k+1})^T (x_{k+1} - x_k) = 0$$
\end{theorem}
\subsubsubsection{Backtracking Line Search}
\begin{definition}[Backtrack Inexact Line Search]
  We make use of the Wolfe Conditions.
  \begin{enumerate}
  \item Initialize $\alpha > 0$, for example, choose $\alpha = 1, c \in (0,1)$
  \item if $(\phi(\alpha) > \phi(0) + c\alpha \phi'(0))$
  \begin{enumerate}
    \item while ($\phi(\alpha) > \phi(0) + c\alpha \phi'(0)$)
    \begin{enumerate}
      \item $\alpha = \alpha / 2$
    \end{enumerate}
  \end{enumerate}
  \item else if ($\phi(2\alpha) \leq \phi(0) + 2c\alpha \phi'(0)$)))
  \begin{enumerate}
    \item while ($\phi(2\alpha) \leq \phi(0) + 2c\alpha \phi'(0)$)
    \begin{enumerate}
      \item $\alpha = 2\alpha$
    \end{enumerate}
  \end{enumerate}
  \item Output $= \alpha$.
\end{enumerate}
\end{definition}
\subsubsubsection{Newton's Method}
In Newton's Method, the search direction is given by $$d_k = -[\nabla^2 f(x_k)]^{-1} \nabla f(x_k)$$
The Newton step is defined only when $\nabla^2 f(x_k)$ is positive definite.
\begin{definition}[Newton's Method]
  Input: Initial point: $x_0$, Tolerance: $\epsilon > 0$
  \begin{enumerate}
    \item Solve the linear system of equations $\nabla^2 f(x_k) d_k = -\nabla f(x_k)$ for $d_k$, so $d_k = -[\nabla^2 f(x_k)]^{-1} \nabla f(x_k)$
    \item Update $x_{k+1} = x_k + \alpha_kd_k$ where $\alpha_k = 1$ for Newton's method
    \item If $\|\nabla f(x_{k+1})\|_2 \leq \epsilon$, stop. Otherwise, go to step 1.
  \end{enumerate}
\end{definition}
\begin{definition}[Operator Norm]
  The operator norm of a matrix $Q \in \mathbb R^{m \times n}$ is defined by 
  $$\|Q\|_2 = \max\{\|Qx\_2: x \in \mathbb R^n, \|x\|_2 = 1\}$$
  This definition satisfies the properties of the norm. For every $A \in \mathbb R^{m \times n}$,
  \begin{itemize}
    \item $\|A\|_2 = 0 \iff A = 0$
    \item $\|\alpha A\|_2 = |\alpha| \|A\|_2$ for every $\alpha \in \mathbb R$
    \item $\|A + B\|_2 \leq \|A\|_2 + \|B\|_2$
  \end{itemize}
\end{definition}
\begin{theorem}[]
  For every $A \in \mathbb R^{m \times n}$, $x \in \mathbb R^n$, we have
  $$\|Ax\|_2 \leq \|A\|_2 \|x\|_2$$
\end{theorem}
\subsubsubsection{Quasi-Newton Methods}
Since computing the Hessian matrix is expensive, we can use an approximation of the Hessian matrix instead. We now set the search direction as
$$d_k = -B_k^{-1} \nabla f(x_k)$$
where the symmetric and positive definite matrix $B_k$ is updated at every iteration by a quasi-Newton updating formula.

\bigskip
There are many quasi-Newton methods, but we will only discuss the BFGS method.

Consider the quadratic model of the objective function:
$$m_k(d) = f(x_k) + \nabla f(x_k)^T d + \frac{1}{2} d^T B_k d$$
where $B_k$ is a positive definite matrix and will be updated at every iteration. The minimizer of this quadratic model is $$d_k = -B_k^{-1} \nabla f(x_k)$$
It is used as the search direction and the new iterate is given by $$x_{k+1} = x_k + \alpha_k d_k$$
where $\alpha_k$ is the step length, chosen so that it satisfies the Wolfe conditions. In this method, we match the gradient of $m_{k+1}$ to the gradient of $f$ at $x_k$ and $x_{k+1}$. That is, we require
$$\nabla m_{k+1}(0) = \nabla f(x_{k+1})$$
$$\nabla m_{k+1}(-\alpha_k d_k) = \nabla f(x_k)$$
From the second equation above, we get
$$\nabla_{k+1}(-\alpha_k d_k) = \nabla f(x_{k+1}) - \alpha_k B_{k+1} d_k = \nabla f(x_k)$$
Which implies
$$\nabla(x_{k+1}) - \nabla f(x_k) = B_{k+1}(x_{k+1} - x_k)$$
This is the secant equation. We can use this equation to update $B_{k+1}$.



\subsubsection{Trust Region Strategy}
The difference in trust region strategy and line search strategy is that in line search strategy, we first choose the direction, then choose step size. In trust region, we first choose the step size, then we choose the direction.
\begin{definition}[Trust Region Strategy]
  In each iteration, we construct a model of $f$. That is, in each step we consider $m_k: \mathbb R^n \to \mathbb R$ that is a simple function that approximates $f$ well on some simple set $\Omega_k$ (the trust region) around our current approximation $x_k$. Then we find the new approximation $$\hat x = \text{argmin } m_k(x) \quad \text{$x \in \Omega_k$}$$
  A common model is the quadratic model $$m_k(x) = f(x_k) + \langle \nabla f(x_k), x - x_k \rangle + \frac{1}{2} \langle x - x_k, B_k(x - x_k) \rangle$$ where $B_k \approx \nabla^2 f(x_k)$ approximates the Hessian. If the values $f(\hat x)$ and $m_k(\hat x)$ are close, then we declare $x_{k+1} = \hat x$. Otherwise, we shrink the size of the trust region $\Omega_k$ and repeat the process.

  Usually $\Omega_k$ is a ball, ellipsoid, or a box around $x_k$.

  The main points are how to choose a model function $m_k$, and how to choose a trust region $\Omega_k$.
\end{definition}



