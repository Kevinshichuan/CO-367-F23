% \documentclass[../main.tex]{subfiles}

% \begin{document}
\subsection{Lecture 3}

\begin{definition}[Matrix Norm]
    \begin{align*}
        \|Q\|=max_{\|x\|=1}\|Qx\|= \text{Largest singular value of A}
    \end{align*}
\end{definition}

\begin{definition}[]
    Define $f,D,\bar{x}$, $D$ is an open set
    Then:
    \begin{enumerate}
        \item Nec: If $\bar{x}$ is a local minimum for $f$ on $D$, then $\nabla f(\bar{x})=0$ and $\nabla^2f(\bar{x}) \succeq 0
        $ is positive semidefinite.
        \item Suff: If $\nabla f(\bar{x})=0,\nabla^2f(\bar{x}) \succ 0
        $ is positive definite then $\bar{x}$ is a strict local minimum of $f$ on $D$.
    \end{enumerate}
\end{definition}
\begin{proof}
    1. updated later after I confirmed some details with the professor
\end{proof}

\begin{definition}[Critical/Stationary Points]
    A point $\bar x \in U$ is a critical point of a function $f: U \rightarrow \mathbb R$ if $\nabla f(\bar x)$ exists and satisfies $\nabla f(\bar x) = 0$.
\end{definition}

\begin{problem}[Algorithm to Find Local Minimizer]
    Given $f: \mathbb{R}\rightarrow \mathbb{R}$ and $f'(\bar{x})\neq 0$, then $x_{new}=\bar{x}-(\text{step})*f'(\bar{x})$.
    
    The idea is that if $f'(\bar x) > 0$, then we know that the function is increasing at $\bar x$, so we want to move to the left to obtain the minimum. Similarly, if $f'(\bar x) < 0$, then we know that the function is decreasing at $\bar x$, so we want to move to the right to obtain the minimum.
\end{problem}

\begin{problem}
    Given f:$\mathbb{R}^n \implies \mathbb{R}, \phi(\epsilon)=f(\bar{x}+\epsilon d)$ 
    \\ using tylar expansion 
    $f(\bar{x}+\epsilon d)$=
    $f(\bar{x})$+$\epsilon$ $\nabla f(\bar{x})^T d$ +$o(\|\epsilon\|)$ \textcolor{red}{shouldnt be $\epsilon d$? or d is the unit vector}

    let $d=-\nabla f(\bar{x})$, f($\bar{x}$)-$\epsilon \| f(\bar{x})\|^2$+$o(\epsilon)$.
    $<f(x)$ (if $\nabla f(\bar{x})\neq 0$)
    \\ i.e test nec condition 
    \\ If $\nabla f(\bar{x})\neq 0$, then $x_{new}=\bar{x}+\epsilon(-\nabla f(\bar(x)))$
    Move to the deapest direction


    
\end{problem}

\begin{definition}[Cauchy's method of steepest descant]
    \text{https://www.math.usm.edu/lambers/mat419/lecture10.pdf}
    $x_{0} \in \mathbb{R}^n$.   
    $$Is \nabla f(x_k)\approxeq 0?\text{IF yes Stop}$$.
    $$O.W, \text{ find a Stop} \alpha >0$$
    $$x_{k+1}=x_k-\alpha\nabla f(x_k)$$
    $$repeat$$
\end{definition}

\begin{problem}[Example of finding global and local minimizers]
    Find global and local minimizers of $f(x,y) = x^3 - 12xy + 8y^3$.
  
    \bigskip
    We first find the gradient and the Hessian:
    $$\nabla f(x,y) = \begin{pmatrix}
      3x^2 - 12y \\
      -12x + 24y^2
    \end{pmatrix}$$
    $$\nabla^2 f(x,y) = \begin{bmatrix}
      -6x & -12 \\
      -12 & 48y
    \end{bmatrix}$$
    We can find the critical points when we solve for $\nabla f(x,y) = 0$. Solving it, we get solutions $(0,0)$ or $(2,1)$.
  
    The Hessian at $(0,0)$ is $$\nabla^2 f(0,0) = \begin{bmatrix}
      0 & -12 \\
      -12 & 0
    \end{bmatrix}$$ The eigenvalues of $\nabla^2 f(0,0)$ are $-12, 12$. Therefore it is indefinite. So $(0,0)$ is a saddle point.
  
    The Hessian at $(2,1)$ is $$\nabla^2 f(2,1) = \begin{bmatrix}
      -12 & -12 \\
      -12 & 48
    \end{bmatrix}$$ Checking all leading principal minors, we see that they are all positive. So $\nabla^2 f(2,1)$ is positive definite. So $(2,1)$ is a local minimizer.
  \end{problem}

% \end{document}